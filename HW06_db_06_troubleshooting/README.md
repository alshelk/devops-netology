# Домашнее задание к занятию 6. «Troubleshooting»

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD-операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести эту операцию:

- напишите список операций, которые вы будете производить для остановки запроса пользователя;
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB.

#### Решение

```text
- список операций для остановки запроса:
        # выполняем поиск операций выполняемых больше 3 минут (180 секунд)
        db.currentOp({"active": true, "secs_running": {"$gt": 180}}) # получаем opid
        # убиваем операцию по найденному opid
        db.killOp(opid)

- как вариант, можно при создании запроса или выполнении команды, методом maxTimeMS, указывать 
время выполнения запроса, при превышении которого, они должны прерываться.  Например:

        db.location.find( { "town": { "$regex": "(Pine Lumber)",
                              "$options": 'i' } } ).maxTimeMS(30)
        
        db.runCommand( { distinct: "collection",
                 key: "city",
                 maxTimeMS: 45 } )
        
так же можно построить соответсвующий индекс при его отсутствии.   
 

```

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причём отношение количества записанных key-value-значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:

- сначала происходит рост отношения записанных значений к истекшим,
- Redis блокирует операции записи.

Как вы думаете, в чём может быть проблема?

##### Решение

```text
Т.к. сначала происходит рост записанных значений, то можно предположить, что последующая 
блокировка связана с механизмом удаления ключей с истекшим сроком действия.

В документации говорится, что при одновременном истечении срока более чем 25% ключей, данный 
механизм может зациклится. Т.е. если в базе много ключей, срок действия которых истекает в одну и туже 
секунду, и они составляют не менее 25% текущей совокупности ключей с установленным сроком действия, Redis
может заблокировать запись, что бы получить процент истекших ключей менее 25%. 
```
 
## Задача 3

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей в таблицах базы
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения этой проблемы вы можете предложить?

#### Решение

```text
  1. Ошибка "Lost connection to MySQL server during query" при росте количества записей, 
возникает при появлении больших и медленных запросов, на обработку которых требуется больше 
времени чем было указано в настройке базы.

- Как вариант решения можно увеличить значение net_read_timeout до времени, которое достаточно для 
завершения передачи данных. Так же стоит включить логирование медленных запросов, выявить их и 
оптимизировать при возможности. Еще стоит обратить внимание: включены ли индексы для участвующих в 
запросе данных. И при необходимости включить их.

  2. Еще такая ошибка может возникнуть, при попытке клиента установить первоначальное соединение. 
Для уточнения этой проблемы стоит выполнить запрос "SHOW GLOBAL STATUS LIKE 'Aborted_connects'".
Aborted_connects увеличивается на 1 за каждую попытку подключения прерванную сервером. Так же 
можно увидеть "reading authorization packet" как часть сообщения об ошибки.

-  Тогда стоит увеличить значение connect_timeout, особенно если медленное соединение.

  3. если причиной ошибки не является одна из описанных выше, то возможно проблемы с BLOB
значениями, превышающими max_allowed_packet. В таком случае может появляться ошибка ER_NET_PACKET_TOO_LARGE.

- Тогда следует увеличить значение max_allowed_packet.



```

## Задача 4


Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объёмом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили эту проблему?

#### Решение

```text
  Данная ошибка указывает на то, что процесс postgres был остановлен из за нехватки памяти.
  
- Для решения проблемы, стоит изучить конфиг postgres и оптимизировать настройки используемой 
памяти, такие как: shared_buffers, work_mem, hash_mem_multiplier. Так же проблема может
быть вызвана слишком большим количеством подключений к серверу, тогда стоит уменьшить max_connections
и вместо этого использовать внешнее по для соединений.
- Так же, если памяти мало, можно увеличить размер подкачки (т.к. killer отрабатывает только тогда, когда
физическая память и пространство подкачки исчерпано).
- Как вариант решение, можно изменить поведение ядра (sysctl -w vm.overcommit_memory=2), хотя
этот параметр не предотвратит вызов killer, он значительно снизит вероятность, что приведет к 
более надежному поведению системы. Или скорректировать оценку killer для конкретного процесса
(echo -1000 > /proc/self/oom_score_adj), что бы он не стал целью OOM killer. Но лучше для начала воспользоваться настройками самого postgres. 
Т.к. возможны ситуации когда нет доступа к настройкам ядра.

```

---